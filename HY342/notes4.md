## HY342 - Παράλληλος Προγραμματισμός
### 20-02-2025 | Διάλεξη 4

#### Πρότυπα Παραλληλισμού 
##### 1. doall ή forall
###### Doall
Ο *Doall* είναι ένας τύπος παραλληλισμού που εφαρμόζεται όταν όλες οι επαναλήψεις ενός βρόχου μπορούν να εκτελεστούν ανεξάρτητα η μία απο την άλλη, χωρίς να υπάρχουν εξαρτήσεις μεταξύ τους. Αυτό σημαίνει ότι όλες οι επαναλήψεις μπορούν να εκτελεστούν ταυτόχρονα, δεδομένου ότι υπάρχουν αρκετοί επεξεργαστές.

**Χαρακτηριστικά:**
1. Δεν υπάρχουν εξαρτήσεις δεδομένων μεταξύ των επαναλήψεων
2. Όλες οι επαναλήψεις εκτελούνται ταυτόχρονα, αν υπάρχει επαρκής υπολογιστική ισχύς
3. Ιδανικό για απόλυτα ενξάρτητους υπολογισμούς.
4. Συχνά εφαρμόζεται σε [SIMD](https://en.wikipedia.org/wiki/Single_instruction,_multiple_data) και [MIMD](https://en.wikipedia.org/wiki/Multiple_instruction,_multiple_data) αρχιτεκτονικές.

###### Forall
Ο *Forall* είναι ο πίο γενικός τρόπος παράλληλης εκτέλεσης βροχών και χρησιμοποιείται κυρίως σε γλώσσες προγραμματισμού υψηλού επιπέδου και αριθμητικούς υπολογισμούς. Σε αντίθεση με το Doall, επιτρέπει συγχρονισμό μεταξύ των επαναλήψεων, αλλα εξακολουθεί να διατηρεί μία παραλληλιστική προσέγγιση.

**Χαρακτηριστικά:**
1. Μπορεί να επιτρέπει κάποιο συγχρονισμό μεταξύ των επαναλήψεων.
2. Χρησιμοποιείται συχνά σε υπολογιστικά συστήματα με διάνυσμα και σε υψηλού επιπέδου γλώσσες προγραμματισμού
3. Εστιάζει στην περιγραφή του υπολογισμού χωρίς να καθορίζει άμεσα την ακολουθιακή ή παράλληλη εκτέλεση.

###### Πότε χρησιμοποιούμε κάθε έναν;
- **Doall**: Όταν κάθε επανάληψη μπορεί να εκτελεστεί χωρίς καμία εξάρτηση από άλλες.
- **Forall**: Όταν υπάρχει κάποια εξάρτηση, άλλα μπορούμε να επιτρέψουμε έναν ελεγχόμενο συγχρονισμό.

###### forall με Pthreads:
- Αρχικός Κώδικας:
```c
for(i = 0; i < 1000000; i++) {
    C[i] = A[i] + B[i];
}
```
- Μετά την μετατροπή:
```c
struct thread_arg {
    int from;
    int to;
    pthread_t thread;
};

void ∗do_work(void ∗voidarg) {
    struct thread_arg ∗arg = (struct thread_arg ∗)voidarg;
    for(i = arg->from; i < arg->to; i++) {
        C[i] = A[i] + B[i];
    }
}

void parallelfor() {
    struct thread_arg[NUM_THREADS];
    int from = 0, to = 1000000;
    int step = to / NUM_THREADS;
    int i ;
    for(i = 0; i < NUM_THREADS; i++) {
        thread_arg[i].from = from;
        thread_arg[i].to = (i < NUM_THREADS-1) ? (from + step) : to;
        from = to;
        pthread_create(&thread_arg[i].thread, NULL, &do_work, &thread_arg[i]);
    }
    for(i = 0; i < NUM_THREADS; i++) {
        pthread_join(thread_arg[i].thread, NULL);
    }
}
```

Ζητήματα:
- Κάθε thread θέλει καινούργιο step
- Κόστος δημιουργίας και join
- Κώδικας βιβλιοθήκης - παράλληλη χρήση παράλληλου κώδικα
- Διαχείριση πόρων

##### 2. Pipeline
Το Pipeline είναι μια τεχνική που χρησιμοποιείται για να διαχωρίσουμε τη δουλειά σε στάδια, με το καθένα από αυτά να εκτελεί μια συγκεκριμένη εργασία. Αντί να εκτελούνται όλες οι εργασίες σειριακά, κάθε στάδιο του pipeline εκτελείται παράλληλα με τα άλλα στάδια, και τα δεδομένα ρέουν μέσα από το pipeline.
Η ιδέα είναι ότι όλα τα βήματα της δουλειάς εκτελούνται ταυτόχρονα, αλλά κάθε βήμα έχει διαφορετικά δεδομένα.
Σκεφτείτε το σαν μια γραμμή παραγωγής: κάθε εργάτης (στάδιο) κάνει τη δουλειά του και περνά το προϊόν (δεδομένα) στον επόμενο εργάτη. Αν όλοι οι εργάτες δουλεύουν ταυτόχρονα, το σύνολο της παραγωγής γίνεται πολύ πιο γρήγορα!

###### Παράδειγμα pipeline
```c
#include<stdio.h>
#include<pthread.h>

queue_t ph1_ph2_buffer;
queue_t ph2_ph3_buffer;

void ∗phase1(void ∗a) {
    while(!done()) {
        read_from_file(data);
        process1(data);
        enqueue(ph1_ph2_buffer, data);
    }
}

void ∗phase2(void ∗a) {
    while(!done()) {
        data = dequeue(ph1_ph2_buffer);
        process2(data);
        enqueue(ph2_ph3_buffer, data);
    }
}

void ∗phase3(void ∗a) {
    while(!done()) {
        data = dequeue(ph2_ph3_buffer);
        save_to_file(data);
    }
}
```

##### 3. Task (recursive)
Το recursive task (αναδρομικό task) είναι μια μέθοδος για να σπάσουμε ένα πρόβλημα σε μικρότερα υποπροβλήματα και να τα επιλύσουμε παράλληλα. Αυτή η μέθοδος είναι συχνά χρήσιμη όταν το πρόβλημα μπορεί να διαχωριστεί σε πολλά υποπροβλήματα που είναι αυτόνομα και παράλληλα εκτελέσιμα.
Πιο ααλυτικά:
- **Task**: Στη βάση του, ένα task είναι ένα ανεξάρτητο "κομμάτι δουλειάς" που μπορεί να εκτελείται παράλληλα με άλλα tasks. Για παράδειγμα, το task μπορεί να είναι μια λειτουργία ή υπολογισμός.
- **Recursive Task**: Σε έναν αναδρομικό παράλληλο αλγόριθμο, το πρόβλημα σπάει σε μικρότερα υποπροβλήματα. Κάθε υποπρόβλημα είναι ένα αναδρομικό task, το οποίο μπορεί να εκτελείται είτε σειριακά είτε παράλληλα με άλλες αναδρομικές κλήσεις.

##### Divide and Conquer
Το Divide and Conquer (Διαίρεση και Κατάκτηση) είναι μια στρατηγική που χρησιμοποιείται για την επίλυση σύνθετων προβλημάτων. Η βασική ιδέα πίσω από αυτή τη στρατηγική είναι ότι μπορούμε να διαιρέσουμε το πρόβλημα σε μικρότερα υποπροβλήματα, να τα επιλύσουμε και μετά να συγκεντρώσουμε τα αποτελέσματα για να λύσουμε το αρχικό πρόβλημα.
Αυτή η τεχνική έχει το πλεονέκτημα ότι τα υποπροβλήματα μπορεί να επιλυθούν παράλληλα, βελτιώνοντας έτσι την απόδοση του αλγορίθμου.

##### 4. MapReduce
Το MapReduce είναι ένα μοντέλο προγραμματισμού και μια αρχιτεκτονική που χρησιμοποιείται για να επεξεργάζεται μεγάλες ποσότητες δεδομένων με παράλληλο τρόπο σε διανεμημένα συστήματα. Το μοντέλο διαχωρίζει τη διαδικασία επεξεργασίας σε δύο βασικά βήματα: το Map και το Reduce.
Ο βασικός στόχος του MapReduce είναι να επιτρέπει την επεξεργασία τεράστιων όγκων δεδομένων σε πολλές μηχανές (όπως σε ένα cluster), έτσι ώστε η επεξεργασία να είναι πιο γρήγορη και αποτελεσματική.


#### Thread Pool
Το thread pool είναι μια τεχνική διαχείρισης νήματος όπου δημιουργούμε έναν πεπερασμένο αριθμό απο threads εκ των προτέρων και τα επαναχρησιμοποιούμε για την εκτέλεση πολλαπλών εργασιών. Αυτό μειώνει το κόστος δημιουργίας και καταστροφής threads, καθιστώντας την εκτέλεση πιο αποδοτική. Χωρίς αυτό θα έπρεπε να δημιουργήσουμε ένα νέο thread για κάθε εργασία που θα οδηγούσε σε **υψηλότερο κόστος δημιουργίας/καταστροφής απο threads**, **πιθανή υπερφόρτωση συστήματος** και **ασυντόνιστη εκτέλεση**.

##### Παράμετροι που το επηρεάζουν:
1. Καλύτερος καταμετρισμός εργασίας
    - Οι εργασίες κατανέμονται όσο το δυνατόν πιο ισόποσα
    - Ενα καλό *Load Balancing* εξασφαλίζει ότι όλα τα threads έχουν παρόμοιο φόρτο εργασίας
2. Περισσότερα κομμάτια
    - Ο κατακερματισμός της εργασίας σε περισσότερα μικρά tasks βοηθά στην καλύτερη εξισορρόπηση
3. Overhead (χρόνος `dequeue()`)
    - Η διαχείριση των εργασιών έχει ένα κόστος (overhead)
    - Άν έχουμε πολλά μικρά tasks μπορεί ο χρόνος διαχείρισης να γίνει μεγαλύτερος απο τον κανονικό χρόνο εκτέλεσης της εργασίας
4. Fine-grain vs Coarse-grain: Ισορροπία
    - Το μέγεθος των tasks που δίνουμε στα threads
    - Διαφέρει απο επεξεργαστή σε επεξεργαστή
    - Fine-Grain:
        - πολλά μικρά tasks
        - Καλύτερη κατανομή φορτίου
        - Υψηλό overhead
    - Coarse-Grain:
        - Λίγα μεγάλα tasks
        - Χαμηλότερο overhead
        κίνδυνος ανισοκατανομής αν τα tasks δεν είναι ίδιας διάρκειας

##### παράδειγμα thread pool:
```c
pthread_t threads[NUM_THREADS];
queue_t available_work;

void∗ worker_thread(void∗ arg) {
    /∗ ... ∗/
    while(!done()) {
        task_t work = dequeue(available_work);
        run(task);
    }
}

int main() {
    /∗ ... ∗/
    for(i = 0; i < NUM_THREADS; i++) {
        pthread_create(&threads[i], NULL, &worker_thread, arg);
    }
    for(i = 0; i < WORK_PIECES; i++) {
        /∗ create work ∗/
        enqueue(available_work, task);
    }
    for(i = 0; i < NUM_THREADS; i++) {
        pthread_join(&threads[i], NULL);
    }
}
```

#### False Sharing
Το False Sharing είναι ένα φαινόμενο στο οποίο πολλά threads τροποποιούν διαφορετικές μεταβλητές που όμως βρίσκονται στην ίδια cache line, οδηγόντας σε περιττές ενημερώσεις μνήμης και μείωση της απόδοσης αφού κάθε φορά που ένα thread θέλει να τροποποιήσει την μεταβλητή του όλα τα άλλα πρέπει να περιμένουν ακόμα και αν έχουν διαφορετική μεταβλητή.
Μπορούμε να το αποφύγουμε κυρίος με δύο τρόπους:
1. memalign
    Μπορούμε να χρησιμοποιήσουμε την συνάρτηση `posix_memalign()` που μας επιτρέπει να δεσμέυσουμε μνήμη που ευθυγραμμίζεται σε πολλαπλάσια ενός αριθμού, π.χ. 64 bytes (ώστε να ταιρίαζε με cache lines). Έχει την δομή:
    ```c
    int posix_memalign(
        void** memptr,
        size_t alignment,
        size_t size
    );
    ```
    - `*memptr`: αποτέλεσμα 
    - `size`: πόσα bytes να δεσμέυσει
    - `allignment`: διέυθυνση πολλαπλάσιο του allignment (δύναμη του 2)
2. padding
Είναι μία απλή τεχνική που προσθέτει έξτρα χώρο ανάμεσα στις μεταβλητές για να τις αναγκάσει να είναι σε διαφορετικές cache lines.