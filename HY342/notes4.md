## HY342 - Παράλληλος Προγραμματισμός
### 20-02-2025 | Διάλεξη 4

#### Πρότυπα Παραλληλισμού 
##### 1. doall ή forall
###### Doall
Ο *Doall* είναι ένας τύπος παραλληλισμού που εφαρμόζεται όταν όλες οι επαναλήψεις ενός βρόχου μπορούν να εκτελεστούν ανεξάρτητα η μία απο την άλλη, χωρίς να υπάρχουν εξαρτήσεις μεταξύ τους. Αυτό σημαίνει ότι όλες οι επαναλήψεις μπορούν να εκτελεστούν ταυτόχρονα, δεδομένου ότι υπάρχουν αρκετοί επεξεργαστές.

**Χαρακτηριστικά:**
1. Δεν υπάρχουν εξαρτήσεις δεδομένων μεταξύ των επαναλήψεων
2. Όλες οι επαναλήψεις εκτελούνται ταυτόχρονα, αν υπάρχει επαρκής υπολογιστική ισχύς
3. Ιδανικό για απόλυτα ενξάρτητους υπολογισμούς.
4. Συχνά εφαρμόζεται σε [SIMD](https://en.wikipedia.org/wiki/Single_instruction,_multiple_data) και [MIMD](https://en.wikipedia.org/wiki/Multiple_instruction,_multiple_data) αρχιτεκτονικές.

###### Forall
Ο *Forall* είναι ο πίο γενικός τρόπος παράλληλης εκτέλεσης βροχών και χρησιμοποιείται κυρίως σε γλώσσες προγραμματισμού υψηλού επιπέδου και αριθμητικούς υπολογισμούς. Σε αντίθεση με το Doall, επιτρέπει συγχρονισμό μεταξύ των επαναλήψεων, αλλα εξακολουθεί να διατηρεί μία παραλληλιστική προσέγγιση.

**Χαρακτηριστικά:**
1. Μπορεί να επιτρέπει κάποιο συγχρονισμό μεταξύ των επαναλήψεων.
2. Χρησιμοποιείται συχνά σε υπολογιστικά συστήματα με διάνυσμα και σε υψηλού επιπέδου γλώσσες προγραμματισμού
3. Εστιάζει στην περιγραφή του υπολογισμού χωρίς να καθορίζει άμεσα την ακολουθιακή ή παράλληλη εκτέλεση.

###### Πότε χρησιμοποιούμε κάθε έναν;
- **Doall**: Όταν κάθε επανάληψη μπορεί να εκτελεστεί χωρίς καμία εξάρτηση από άλλες.
- **Forall**: Όταν υπάρχει κάποια εξάρτηση, άλλα μπορούμε να επιτρέψουμε έναν ελεγχόμενο συγχρονισμό.

###### forall με Pthreads:
- Αρχικός Κώδικας:
```c
for(i = 0; i < 1000000; i++) {
    C[i] = A[i] + B[i];
}
```
- Μετά την μετατροπή:
```c
struct thread_arg {
    int from;
    int to;
    pthread_t thread;
};

void ∗do_work(void ∗voidarg) {
    struct thread_arg ∗arg = (struct thread_arg ∗)voidarg;
    for(i = arg->from; i < arg->to; i++) {
        C[i] = A[i] + B[i];
    }
}

void parallelfor() {
    struct thread_arg[NUM_THREADS];
    int from = 0, to = 1000000;
    int step = to / NUM_THREADS;
    int i ;
    for(i = 0; i < NUM_THREADS; i++) {
        thread_arg[i].from = from;
        thread_arg[i].to = (i < NUM_THREADS-1) ? (from + step) : to;
        from = to;
        pthread_create(&thread_arg[i].thread, NULL, &do_work, &thread_arg[i]);
    }
    for(i = 0; i < NUM_THREADS; i++) {
        pthread_join(thread_arg[i].thread, NULL);
    }
}
```

Ζητήματα:
- Κάθε thread θέλει καινούργιο step
- Κόστος δημιουργίας και join
- Κώδικας βιβλιοθήκης - παράλληλη χρήση παράλληλου κώδικα
- Διαχείριση πόρων

##### 2. Pipeline
##### 3. Task (recursive)
##### 4. MapReduce

#### Thread Pool
Το thread pool είναι μια τεχνική διαχείρισης νήματος όπου δημιουργούμε έναν πεπερασμένο αριθμό απο threads εκ των προτέρων και τα επαναχρησιμοποιούμε για την εκτέλεση πολλαπλών εργασιών. Αυτό μειώνει το κόστος δημιουργίας και καταστροφής threads, καθιστώντας την εκτέλεση πιο αποδοτική. Χωρίς αυτό θα έπρεπε να δημιουργήσουμε ένα νέο thread για κάθε εργασία που θα οδηγούσε σε **υψηλότερο κόστος δημιουργίας/καταστροφής απο threads**, **πιθανή υπερφόρτωση συστήματος** και **ασυντόνιστη εκτέλεση**.

##### Παράμετροι που το επηρεάζουν:
1. Καλύτερος καταμετρισμός εργασίας
    - Οι εργασίες κατανέμονται όσο το δυνατόν πιο ισόποσα
    - Ενα καλό *Load Balancing* εξασφαλίζει ότι όλα τα threads έχουν παρόμοιο φόρτο εργασίας
2. Περισσότερα κομμάτια
    - Ο κατακερματισμός της εργασίας σε περισσότερα μικρά tasks βοηθά στην καλύτερη εξισορρόπηση
3. Overhead (χρόνος `dequeue()`)
    - Η διαχείριση των εργασιών έχει ένα κόστος (overhead)
    - Άν έχουμε πολλά μικρά tasks μπορεί ο χρόνος διαχείρισης να γίνει μεγαλύτερος απο τον κανονικό χρόνο εκτέλεσης της εργασίας
4. Fine-grain vs Coarse-grain: Ισορροπία
    - Το μέγεθος των tasks που δίνουμε στα threads
    - Διαφέρει απο επεξεργαστή σε επεξεργαστή
    - Fine-Grain:
        - πολλά μικρά tasks
        - Καλύτερη κατανομή φορτίου
        - Υψηλό overhead
    - Coarse-Grain:
        - Λίγα μεγάλα tasks
        - Χαμηλότερο overhead
        κίνδυνος ανισοκατανομής αν τα tasks δεν είναι ίδιας διάρκειας

##### παράδειγμα thread pool:
```c
pthread_t threads[NUM_THREADS];
queue_t available_work;

void∗ worker_thread(void∗ arg) {
    /∗ ... ∗/
    while(!done()) {
        task_t work = dequeue(available_work);
        run(task);
    }
}

int main() {
    /∗ ... ∗/
    for(i = 0; i < NUM_THREADS; i++) {
        pthread_create(&threads[i], NULL, &worker_thread, arg);
    }
    for(i = 0; i < WORK_PIECES; i++) {
        /∗ create work ∗/
        enqueue(available_work, task);
    }
    for(i = 0; i < NUM_THREADS; i++) {
        pthread_join(&threads[i], NULL);
    }
}
```

#### False Sharing
Το False Sharing είναι ένα φαινόμενο στο οποίο πολλά threads τροποποιούν διαφορετικές μεταβλητές που όμως βρίσκονται στην ίδια cache line, οδηγόντας σε περιττές ενημερώσεις μνήμης και μείωση της απόδοσης αφού κάθε φορά που ένα thread θέλει να τροποποιήσει την μεταβλητή του όλα τα άλλα πρέπει να περιμένουν ακόμα και αν έχουν διαφορετική μεταβλητή.
